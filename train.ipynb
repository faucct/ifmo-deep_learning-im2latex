{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from src.tree_parser import *\n",
    "from src.tree_sequencing import *\n",
    "from src.model import *\n",
    "\n",
    "def iter_trees():\n",
    "    with open(\"tmp/im2latex_formulas1.tree\", \"rb\") as lines1:\n",
    "        with open(\"tmp/im2latex_formulas2.tree\", \"rb\") as lines2:\n",
    "            for elements in iter_tree_lines(itertools.chain(lines1, lines2)):\n",
    "                try:\n",
    "                    yield list(iter_elements(elements)) if elements else []\n",
    "                except Exception as err:\n",
    "                    print(\"WTF\")\n",
    "                    print(b''.join(elements).decode())\n",
    "                    raise\n",
    "\n",
    "\n",
    "class TreeMatcherVisitor(Visitor):\n",
    "    def __init__(self, with_children_filter=lambda _: True, symbol_filter=lambda _: True):\n",
    "        self.is_ok = True\n",
    "        self.with_children_filter = with_children_filter\n",
    "        self.symbol_filter = symbol_filter\n",
    "\n",
    "    def visit_with_children(self, with_children):\n",
    "        if not self.with_children_filter(with_children.header):\n",
    "            self.is_ok = False\n",
    "\n",
    "    def visit_symbol(self, symbol):\n",
    "        if not self.symbol_filter(symbol.symbol):\n",
    "            self.is_ok = False\n",
    "            \n",
    "def tree_matches(elements, **kwargs):\n",
    "    visitor = TreeMatcherVisitor(**kwargs)\n",
    "    AllVisitor(visitor).visit_list(elements)\n",
    "    return visitor.is_ok\n",
    "\n",
    "class TotalAndDocumentFrequencyCounter:\n",
    "    def __init__(self):\n",
    "        self.total = Counter()\n",
    "        self.document_frequency = Counter()\n",
    "\n",
    "    def __call__(self, key, count):\n",
    "        self.total[key] += count\n",
    "        self.document_frequency[key] += 1\n",
    "        return self\n",
    "\n",
    "class StripInvisibleVisitor(Visitor):\n",
    "    def visit_symbol(self, symbol):\n",
    "        return symbol_is_invisible(symbol.symbol)\n",
    "\n",
    "def strip_invisible(elements):\n",
    "    return [\n",
    "        element\n",
    "        for element in elements\n",
    "        if not element.visit(StripInvisibleVisitor())\n",
    "    ]\n",
    "\n",
    "def symbol_is_invisible(symbol):\n",
    "    return\\\n",
    "        symbol.startswith(b'\\\\write1{\\\\newlabel{')\\\n",
    "            or symbol in [\n",
    "                b'\\\\kern 0.0\\n',\n",
    "                b'\\\\kern0.0\\n',\n",
    "                b'\\\\glue 0.0\\n',\n",
    "            ]\n",
    "\n",
    "def default_with_children_filter(header):\n",
    "    if header.startswith((b'\\\\vbox', b'\\\\hbox')):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "            \n",
    "def default_symbol_filter(symbol):\n",
    "    if symbol_is_invisible(symbol):\n",
    "        return False\n",
    "    if symbol.startswith((b'\\\\hbox', b'\\\\vbox', b'\\\\kern')):\n",
    "        return False\n",
    "    elif symbol.startswith(b'\\\\glue') and symbol not in [\n",
    "            b'\\\\glue(\\\\mskip) 3.0mu\\n',\n",
    "            b'\\\\glue 3.33333 plus 1.66666 minus 1.11111\\n',\n",
    "            b'\\\\glue(\\\\mskip) 5.0mu plus 5.0mu\\n',\n",
    "            b'\\\\glue 10.00002\\n',\n",
    "            b'\\\\glue 20.00003\\n',\n",
    "            b'\\\\glue(\\\\mskip) -3.0mu\\n',\n",
    "            b'\\\\glue(\\\\mskip) 4.0mu plus 2.0mu minus 4.0mu\\n',\n",
    "            b'\\\\glue 0.0 plus 1.0fil\\n',\n",
    "            b'\\\\glue 28.45274\\n',\n",
    "            b'\\\\glue 14.22636\\n',\n",
    "            b'\\\\glue 56.9055\\n',\n",
    "    ]:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def base_tree_filter(tree):\n",
    "    return tree_matches(\n",
    "        tree,\n",
    "        with_children_filter=default_with_children_filter,\n",
    "        symbol_filter=default_symbol_filter,\n",
    "    )\n",
    "\n",
    "class SymbolCounterVisitor(Visitor):\n",
    "    def __init__(self):\n",
    "        self.counter = Counter()\n",
    "\n",
    "    def visit_symbol(self, symbol):\n",
    "        self.counter[symbol.symbol] += 1\n",
    "\n",
    "def count_symbols(counter, elements):\n",
    "    visitor = SymbolCounterVisitor()\n",
    "    AllVisitor(visitor).visit_list(elements)\n",
    "    for key, count in visitor.counter.items():\n",
    "        counter(key, count)\n",
    "    return counter\n",
    "\n",
    "class FrequencyFilter:\n",
    "    def __init__(self, counter, limit):\n",
    "        self.counter = counter\n",
    "        self.limit = limit\n",
    "    \n",
    "    def __call__(self, key):\n",
    "        return self.counter[key] > self.limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "symbol_counter = reduce(count_symbols, map(strip_invisible, iter_trees()), TotalAndDocumentFrequencyCounter())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tree_is_sequenceable(tree):\n",
    "    return base_tree_filter(tree) \\\n",
    "        and tree_matches(\n",
    "            tree,\n",
    "            symbol_filter=FrequencyFilter(symbol_counter.document_frequency, 1000),\n",
    "        ) \\\n",
    "        and len(elements_to_sequence(tree)) < 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('tmp/image_ids.lst') as image_ids:\n",
    "    sequence_with_image_id = [\n",
    "        (image_id[:-1] + \".png\", elements_to_sequence(tree))\n",
    "        for image_id, tree in zip(image_ids, map(strip_invisible, iter_trees()))\n",
    "        if tree_is_sequenceable(tree)\n",
    "    ]\n",
    "token_encoder = LabelEncoder()\n",
    "token_encoder.fit(['EOS', 'SOS'] + list({\n",
    "    token\n",
    "    for image_id, sequence in sequence_with_image_id\n",
    "    for token in sequence\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "flow = TrainingSequence(sequence_with_image_id, token_encoder)\n",
    "max_sequence_length = flow.max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "images_input = keras.layers.Input(shape=(256, 256, 1), dtype='uint8')\n",
    "seq = images_seq(images_input)\n",
    "seq_mean = keras.layers.Lambda(\n",
    "    keras.backend.mean,\n",
    "    arguments={'axis': 1},\n",
    "    output_shape=(seq.shape.dims[0], seq.shape.dims[2]),\n",
    ")(seq)\n",
    "h0 = keras.layers.Dense(512, activation='tanh')(seq_mean)\n",
    "o0 = keras.layers.Dense(512, activation='tanh')(seq_mean)\n",
    "vocab_size = len(token_encoder.classes_)\n",
    "\n",
    "# 1. get token embeddings\n",
    "dim = 80\n",
    "sequences_input = keras.Input((max_sequence_length,), dtype='int32')\n",
    "tok_embeddings = keras.layers.Embedding(vocab_size, dim, dtype='float32')(sequences_input)\n",
    "\n",
    "# 2. add the special <sos> token embedding at the beggining of every formula\n",
    "\n",
    "# 3. decode\n",
    "attn_cell = keras.layers.RNN(\n",
    "    AttentionCell(keras.layers.LSTMCell(512), seq, vocab_size),\n",
    "    return_sequences=True,\n",
    ")\n",
    "model = keras.models.Model(\n",
    "    [images_input, sequences_input],\n",
    "    attn_cell(tok_embeddings),\n",
    ")\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(flow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}